# NgramLanguageModel
This project builds a Bigram Language Model (2-gram) using Natural Language Processing (NLP) techniques, with support for Laplace smoothing and Good-Turing smoothing to handle unseen word sequences. It runs in a Streamlit web app where users can interactively upload text, analyze bigram probabilities, and compare smoothing methods.
